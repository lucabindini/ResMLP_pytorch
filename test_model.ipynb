{"cells":[{"cell_type":"markdown","metadata":{"id":"mIJ5fagihR66"},"source":["# ResMLP\n","#### Feedforward networks for image classification written in PyTorch"]},{"cell_type":"markdown","metadata":{"id":"wzfOTRphhR7B"},"source":["### Import and install extra libraries\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3J8ImseAhR7C"},"outputs":[],"source":["import torch\n","import torch.backends.cudnn as cudnn\n","import csv\n","\n","!pip install timm einops\n","from timm import optim\n","from timm import models\n","\n","import dataset\n","from model import ResMLP\n","import learning_utils"]},{"cell_type":"markdown","metadata":{"id":"BIwNPl9HhR7J"},"source":["### Setting device (CPU or GPU)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZDjfQkPnhR7K"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'Using {device} device')"]},{"cell_type":"markdown","metadata":{"id":"iPifR49Idnfy"},"source":["### Build model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-uHkEWdIhR7F"},"outputs":[],"source":["# ResNet18 Timm implementation\n","teacher_model = models.resnet.ResNet(block=models.resnet.BasicBlock, layers=[2, 2, 2, 2], num_classes=10)\n","\n","# CaiT Timm implementation\n","#transformer_model = models.cait.Cait(img_size=96, num_classes=10)\n","\n","# ResMLP12 Timm implementation\n","#student_model = models.mlp_mixer.MlpMixer(num_classes=10, img_size=96, patch_size=16, num_blocks=12, embed_dim=384, mlp_ratio=4, block_layer=models.mlp_mixer.ResBlock, norm_layer=models.mlp_mixer.Affine)\n","\n","# ResMLP12 local implementation\n","student_model = ResMLP(in_channels=3, image_size=96, patch_size=16, num_classes=10, dim=384, depth=12).to(device)\n","\n","if device == 'cuda':\n","        student_model = torch.nn.DataParallel(student_model)\n","        teacher_model = torch.nn.DataParallel(teacher_model)\n","        cudnn.benchmark = True"]},{"cell_type":"markdown","metadata":{"id":"n_Q3m-v9fev4"},"source":["### Loss and optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"94MhqSFVfkuo"},"outputs":[],"source":["# Loss function\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","# Adam optimizer for teacher convnet \n","teacher_optimizer = torch.optim.AdamW(teacher_model.parameters(), lr=1e-3, weight_decay=0.05)\n","\n","# Lamb optimizer for ResMLP12\n","student_optimizer = optim.Lamb(student_model.parameters(), lr=5e-3, weight_decay=0.2)"]},{"cell_type":"code","source":["num_epochs = 50\n","\n","with open('performance_without_distillation.csv', 'w', newline='') as f:\n","    writer = csv.writer(f)\n","    writer.writerow(['epoch', 'train loss', 'test loss',\n","                     'train accuracy', 'test accuracy'])\n","train_loss, train_accuracy, test_loss, test_accuracy = 0,0,0,0\n","for t in range(num_epochs):\n","    print(f'Epoch {t+1}\\n-------------------------------')\n","    train_loss, train_accuracy = learning_utils.train_teacher(dataset.train_dataloader, student_model, device, loss_fn, student_optimizer)\n","    test_loss, test_accuracy = learning_utils.test(dataset.test_dataloader, student_model, device, loss_fn)\n","    with open('performance_without_distillation.csv', 'a', newline='') as f:\n","        writer = csv.writer(f)\n","        writer.writerow([t, f'{train_loss:f}', f'{test_loss:f}',\n","                         f'{train_accuracy:f}', f'{test_accuracy:f}'])"],"metadata":{"id":"rfnRv17rRZjo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9xnbQYjDjZLJ"},"source":["### Execute with train distillation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"06K8Jj0cjekp"},"outputs":[],"source":["num_epochs = 50\n","\n","for t in range(num_epochs):\n","    print(f'Epoch {t+1}\\n-------------------------------')\n","    train_loss, train_accuracy = learning_utils.train(dataset.train_dataloader, teacher_model, device, loss_fn, teacher_optimizer)\n","    test_loss, test_accuracy = learning_utils.test(dataset.test_dataloader, teacher_model, device, loss_fn)\n","\n","with open('performance_with_distillation.csv', 'w', newline='') as f:\n","    writer = csv.writer(f)\n","    writer.writerow(['epoch', 'train loss', 'test loss',\n","                     'train accuracy', 'test accuracy'])\n","train_loss, train_accuracy, test_loss, test_accuracy = 0,0,0,0\n","for t in range(num_epochs):\n","    print(f'Epoch {t+1}\\n-------------------------------')\n","    train_loss, train_accuracy = learning_utils.train_student(dataset.train_dataloader, student_model, teacher_model, device, loss_fn, student_optimizer)\n","    test_loss, test_accuracy = learning_utils.test(dataset.test_dataloader, student_model, device, loss_fn)\n","    with open('performance_with_distillation.csv', 'a', newline='') as f:\n","        writer = csv.writer(f)\n","        writer.writerow([t, f'{train_loss:f}', f'{test_loss:f}',\n","                         f'{train_accuracy:f}', f'{test_accuracy:f}'])"]},{"cell_type":"markdown","metadata":{"id":"p1AYNg4gdnf2"},"source":["### Save the model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XpsH8inWdnf2"},"outputs":[],"source":["torch.save(student_model.state_dict(), 'saved_model.pth')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"test_model.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}